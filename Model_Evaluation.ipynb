{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "This script evaluates the performance of the air pollution prediction GAM.\n",
    "\n",
    "As input are needed:\n",
    "- the name of the chosen variable (i.e. air pollutant)\n",
    "- a dataframe containing the observations of weather variables and air pollutants (as produced by the script \"Generate Variables\")\n",
    "- a dataframe containing the selected explanatory variables for the models for each station (as produced by the script \"Model Selection\")\n",
    "\n",
    "## Load Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import shapefile as shp\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "from pygam import LinearGAM, LogisticGAM, s, f,l, GAM, te\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime\n",
    "import math\n",
    "import sklearn.mixture as mix\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import re\n",
    "from scipy import stats\n",
    "from functions import GAMf, time_plot_conf, curves, GAMf_train_test\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from dictionaries import starts, ends, che_classes, beijing_classes, wuhan_classes, at_classes, loc_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'che'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set matplotplit style\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose pollutant to examine\n",
    "in_var = 'no2'\n",
    "IN_VAR = in_var.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataframe with chosen variables as produced by the variable selection algorithm\n",
    "chosen_vars = pd.read_csv('./' + loc+  '/' +in_var+'_chosen_vars.csv', index_col =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset of explanatory & independent variables observations as produced by the variable generation script\n",
    "data_path =  './' + loc +'/' + 'df_' + loc + '2.csv'\n",
    "df = pd.read_csv(data_path, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert index to datetime format\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we are working with a log normal distribution, 0 values for the independent variable cannot be processed \n",
    "# they are replaced by a very low non zero number\n",
    "df[in_var] = df[in_var].replace(0,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns with NaN values, infinite values or values negative values for the observed variable\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna(subset=[in_var])\n",
    "df = df.drop(df[df[in_var]<0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vector with names of all cities\n",
    "cities = np.unique(df['city'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Evaluation\n",
    "\n",
    "To evaluate the model performance we perform cross validation with the data for the year 2019. Taking into account the temporal dependencies in the air pollution data, the models for different stations are fitted on 3, 6, 9, 12, 18 and 24 months of train data prior to a chosen date and tested on the data from the subsequent month. The chosen cut-off date is the start of each month in the year 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load potential classes\n",
    "classes = loc_classes[loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_vars_all = ['t', 'h', 'ws', 'dew',\n",
    " 'pca', 'lagpca_year', 'lagpca_halfyear', 'lagpca_12weeks', 'lagpca_8weeks',\n",
    " 'lagpca_4weeks', 'lagpca_2weeks', 'lagpca_1week', 'lagws_4weeks',\n",
    " 'lagws_2weeks', 'lagws_1week', 'lagws_4weeks_max', 'lagws_2weeks_max',\n",
    " 'lagws_1week_max', 'year', 'weekday', 'month', 'wx', 'wy', 'julian', 'h_lag1',\n",
    " 't_lag1', 'wx_lag1', 'wy_lag1', 'ws_lag1', 'dew_lag1', 'h_lag2', 't_lag2',\n",
    " 'wx_lag2', 'wy_lag2', 'ws_lag2', 'dew_lag2', 'h_lag3', 't_lag3', 'wx_lag3',\n",
    " 'wy_lag3', 'ws_lag3', 'dew_lag3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate column names for output dataframe\n",
    "col_names = []\n",
    "model_names = []\n",
    "for i in range(1,13):\n",
    "    col_names.append('RMSE_train_'+str(i))\n",
    "    col_names.append('RMSE_test_'+str(i))\n",
    "    col_names.append('R_squared_'+str(i))\n",
    "    col_names.append('FAC2_'+str(i))\n",
    "    col_names.append('testdays_'+str(i))\n",
    "    col_names.append('traindays_'+str(i))\n",
    "    col_names.append('ratio_'+str(i))\n",
    "    col_names.append('avg_err_'+str(i))\n",
    "    model_names.append('model_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate gam models with the respectively chosen variables & predict the different months in 2019\n",
    "# predictions are only made when training data contains at least one year of data!\n",
    "out = pd.DataFrame(data = None, index = cities, columns = col_names)\n",
    "out_gam = pd.DataFrame(data = None, index = cities, columns = model_names)\n",
    "preds_all = pd.DataFrame(data = None, index = cities, columns = model_names)\n",
    "\n",
    "whisker_data = pd.DataFrame(data = None)\n",
    "\n",
    "crossV_train = pd.DataFrame(data =None, index = cities, columns = [3,6,9,12,18,24])\n",
    "crossV_test = pd.DataFrame(data =None, index = cities, columns = [3,6,9,12,18,24])\n",
    "\n",
    "\n",
    "for i in range(1,13):\n",
    "    for j in [3,6,9,12,18,24]:\n",
    "        for city in cities:\n",
    "            ex_vars = chosen_vars.loc[city].dropna().values.tolist()\n",
    "            # ex_vars.append('weekday')\n",
    "            cut = str(i) + '/' + str(1)+ '/' + str(2019)\n",
    "            \n",
    "            #if 'weekday' not in chosen_vars:\n",
    "            ex_vars.append('weekday')\n",
    "        \n",
    "            out_gam.loc[city, model_names[i-1]], out.loc[city, col_names[8*i-8]:col_names[8*i-1]], preds_all.at[city, model_names[i-1]] =  GAMf_train_test(df, in_var, ex_vars, city, cut,pred_end = 'one_month', train_duration = j)\n",
    "            \n",
    "            \n",
    "            whisker_list = [city, j, out.loc[city, col_names[8*(i-1)]], out.loc[city, col_names[8*(i-1)+1]], classes[city]]\n",
    "            whisker_data = whisker_data.append([whisker_list])\n",
    "            \n",
    "            \n",
    "        crossV_train[j] = out.loc[:, out.columns.str.startswith('RMSE_train')].mean(axis=1)\n",
    "        crossV_test[j] = out.loc[:, out.columns.str.startswith('RMSE_test')].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "whisker_data = whisker_data.rename(columns={0:'city', 1: 'train_len', 2:'train_RMSE', 3:'test_RMSE', 4: 'class'})\n",
    "whisker_data['train_len'] = whisker_data['train_len'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hicom\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n",
      "C:\\Users\\hicom\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\hicom\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# calculate mean, maximum value and minimum value for each station\n",
    "city_mean = pd.Series(data= None, index = cities)\n",
    "city_max = pd.Series(data= None, index = cities)\n",
    "city_min = pd.Series(data= None, index = cities)\n",
    "\n",
    "# add columns with the mean, max and min values\n",
    "for city in cities:\n",
    "    df_city = df[df['city']==city]\n",
    "    df_city =df_city[df_city.index.year >= 2017]\n",
    "    \n",
    "    city_mean.loc[city] = df_city[df_city.index.year < 2020][in_var].mean()\n",
    "    city_max.loc[city] = df_city[df_city.index.year <2020][in_var].max()\n",
    "    city_min.loc[city] = df_city[df_city.index.year <2020][in_var].min()\n",
    "\n",
    "out['mean'] = city_mean\n",
    "out['max'] = city_max\n",
    "out['min'] = city_min\n",
    "out['diff'] = out['max'] - out['min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Relative RMSE</th>\n",
       "      <th>R_Squared</th>\n",
       "      <th>FAC2</th>\n",
       "      <th># of Days predicted</th>\n",
       "      <th># of Days used for training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Opfikon_Balsberg</th>\n",
       "      <td>8.29</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29.25</td>\n",
       "      <td>726.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StGallen_Blumenbergplatz</th>\n",
       "      <td>10.41</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>28.92</td>\n",
       "      <td>723.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StGallen_Stuelegg</th>\n",
       "      <td>2.90</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.97</td>\n",
       "      <td>29.25</td>\n",
       "      <td>726.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuerich_Schimmelstrasse</th>\n",
       "      <td>8.69</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29.25</td>\n",
       "      <td>724.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuerich_Stampfenbachstrasse</th>\n",
       "      <td>8.81</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29.25</td>\n",
       "      <td>726.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>7.82</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.99</td>\n",
       "      <td>29.18</td>\n",
       "      <td>725.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              RMSE  Relative RMSE  R_Squared  FAC2  \\\n",
       "Opfikon_Balsberg              8.29           0.10       0.67  1.00   \n",
       "StGallen_Blumenbergplatz     10.41           0.12       0.72  1.00   \n",
       "StGallen_Stuelegg             2.90           0.06       0.61  0.97   \n",
       "Zuerich_Schimmelstrasse       8.69           0.10       0.73  1.00   \n",
       "Zuerich_Stampfenbachstrasse   8.81           0.11       0.72  1.00   \n",
       "Mean                          7.82           0.10       0.69  0.99   \n",
       "\n",
       "                             # of Days predicted  # of Days used for training  \n",
       "Opfikon_Balsberg                           29.25                       726.58  \n",
       "StGallen_Blumenbergplatz                   28.92                       723.92  \n",
       "StGallen_Stuelegg                          29.25                       726.58  \n",
       "Zuerich_Schimmelstrasse                    29.25                       724.58  \n",
       "Zuerich_Stampfenbachstrasse                29.25                       726.58  \n",
       "Mean                                       29.18                       725.65  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot table with summary data\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "out_summary = pd.DataFrame(data = None, index = cities, columns = ['RMSE', 'Relative RMSE', 'R_Squared', 'FAC2', '# of Days predicted', '# of Days used for training'])\n",
    "\n",
    "out_summary['RMSE'] = out.loc[:, out.columns.str.startswith('RMSE_test')].mean(axis=1)\n",
    "out_summary['Relative RMSE'] = out.loc[:, out.columns.str.startswith('RMSE_test')].mean(axis=1)/out['diff']\n",
    "out_summary['R_Squared'] = out.loc[:, out.columns.str.startswith('R_squared')].mean(axis=1)\n",
    "out_summary['FAC2'] = out.loc[:, out.columns.str.startswith('FAC2')].mean(axis=1)\n",
    "out_summary['# of Days predicted'] = out.loc[:, out.columns.str.startswith('testdays')].mean(axis=1)\n",
    "out_summary['# of Days used for training'] = out.loc[:, out.columns.str.startswith('traindays')].mean(axis=1)\n",
    "out_summary.loc['Mean',:]= out_summary.mean(axis=0)\n",
    "\n",
    "\n",
    "out_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average root mean squared error over all stations & months is: 6.990010864942926\n",
      "The average pseudo R-squared over all stations & months is: 0.6890815551150257\n",
      "The average difference between prediction & true value over all stations & months is: -0.17794840179512086\n",
      "The average FAC2 score over all stations & months is: 0.994861643252448\n",
      "The average value of no2  over all stations & months is:  29.410354574885936\n"
     ]
    }
   ],
   "source": [
    "# calculate average statistics over all models\n",
    "\n",
    "rmse_cols = [col for col in out.columns if 'RMSE' in col]\n",
    "r_squared_cols = [col for col in out.columns if 'R_squared' in col]\n",
    "avg_err_cols = [col for col in out.columns if 'avg_err' in col]\n",
    "fac2_cols = [col for col in out.columns if 'FAC2' in col]\n",
    "\n",
    "\n",
    "#avg_rmse = out[rmse_cols].mean().mean()\n",
    "avg_r_squared = out[r_squared_cols].mean().mean()\n",
    "avg_err = out[avg_err_cols].mean().mean()\n",
    "avg_fac2 = out[fac2_cols].mean().mean()\n",
    "mean_in_var = df[df.index < datetime.strptime('03/16/2020', '%m/%d/%Y')][in_var].mean()\n",
    "\n",
    "\n",
    "print('The average root mean squared error over all stations & months is:', out[rmse_cols].mean(axis=1).mean())\n",
    "print('The average pseudo R-squared over all stations & months is:', avg_r_squared)\n",
    "print('The average difference between prediction & true value over all stations & months is:', avg_err)\n",
    "print('The average FAC2 score over all stations & months is:', avg_fac2)\n",
    "print('The average value of', in_var,' over all stations & months is: ', mean_in_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth Graph Plot\n",
    "\n",
    "Plots the partial dependencies of the independet variable with the explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4945c06a48b74b49a1197116b87ead58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='city', options=('Opfikon_Balsberg', 'StGallen_Blumenbergplatz', 'Sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot smooth graph\n",
    "\n",
    "@interact\n",
    "def curve_plots(city = cities):\n",
    "    gam_model = out_gam.loc[city,'model_12']\n",
    "    ex_vars = chosen_vars.loc[city].dropna().values.tolist()\n",
    "    ex_vars.append('weekday')\n",
    "    curves(gam_model, ex_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisker_data.to_csv('C:/Users/hicom/Documents/GitHub/corona-pollution/Final/open/'+loc+'/'+in_var+'_whisker.csv')\n",
    "out.to_csv('C:/Users/hicom/Documents/GitHub/corona-pollution/Final/open/'+loc+'/'+in_var+'_out.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
