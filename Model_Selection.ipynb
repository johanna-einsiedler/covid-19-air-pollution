{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "This script runs the model selection algorithm on on a provided dataset.\n",
    "\n",
    "#### Key Indicators\n",
    "For the selection of the model covariates we use a forward elimination procedure. Two key indicators are used for the model selection: the Akaike Information Criterion (AIC) and the Variance Inflation Factor (VIF). The AIC is an estimate of the in-sample prediction error that is commonly used to compare the quality of different statistical models for a given data. The aim of the indicator is to regularize the model by balancing the goodness-of-fit against model complexity and thereby avoiding both underfitting and overfitting. The AIC is calculated as follows:\n",
    "$$\n",
    "AIC = 2k - \\ln(l),\n",
    "$$\n",
    "\\noindent where $k$ is the number of model parameters, and $l$ denotes the maximum value of the model likelihood.\n",
    "\n",
    "The VIF measures the degree of collinearity between independent variables, \\ie if they have a close to linear relationship and are thus not independent from each other. Collinearity may cause problems in regression-like techniques as it inflates the variance of regression parameters and thus may lead to wrong identification of the relevant predictors. The \n",
    "$$\n",
    "VIF = 1 / (1-R^2_i),\n",
    "$$\n",
    "\\noindent where $R^2_i$ is the coefficient of determination of the regression of the $i$-th variable with all other explanatory variables.\n",
    "\n",
    "#### Model Selection Algorithm\n",
    "Our implementation of the model selection algorithm closely follows \\cite{Barmpadimos11}. The algorithm executes as follows: (1) For each explanatory variable we fit a GAM model comprising just this single variable. The model with the lowest AIC is selected. (2) We iteratively search for the next best variable to be added to the existing model. Variables with $VIF >2.5$ are filtered out. Among the constructed candidate models, the one with the lowest AIC is chosen. The threshold of $2.5$ corresponds to the coefficient of determination $R^2=0.6$.\n",
    "\n",
    "\n",
    "## Load Libraries & Data\n",
    "\n",
    "The input needed for this script is a dataframe containing all potential explanatory variables for each day of observation - such a dataframe can be created from any dataframe with weather data using the \"Generate Variables\" Script. In addition to the explanatory variables it should also contain data about the independent variable (i.e. the pollutant) that should be analysed. If the dataset contains multiple pollutant variables, the variable of interest can be chosen by specifying 'in_var' accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import shapefile as shp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pygam import LinearGAM, LogisticGAM, s, f,l, GAM, te\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime\n",
    "import math\n",
    "import sklearn.mixture as mix\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import re\n",
    "from scipy import stats\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dictionaries import starts, ends, che_classes, beijing_classes, wuhan_classes, at_classes, loc_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data \n",
    "data_path = '.che/df_che2.csv'\n",
    "df = pd.read_csv(data_path, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert index to datetime format\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities contained in the dataset: ['Opfikon_Balsberg' 'StGallen_Blumenbergplatz' 'StGallen_Stuelegg'\n",
      " 'Zuerich_Schimmelstrasse' 'Zuerich_Stampfenbachstrasse']\n"
     ]
    }
   ],
   "source": [
    "# get vector with names of all the cities\n",
    "cities = np.unique(df['city'].values)\n",
    "print('Cities contained in the dataset:',cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables available in the dataset: ['pm10' 'sun' 't' 'o3' 'no2' 'nox' 'no' 'ws' 'wd' 'press' 'h' 'pm25' 'co'\n",
      " 'p' 'so2' 'city' 'dew' 'pca' 'lagpca_year' 'lagpca_halfyear'\n",
      " 'lagpca_12weeks' 'lagpca_8weeks' 'lagpca_4weeks' 'lagpca_2weeks'\n",
      " 'lagpca_1week' 'lagws_4weeks' 'lagws_2weeks' 'lagws_1week'\n",
      " 'lagws_4weeks_max' 'lagws_2weeks_max' 'lagws_1week_max' 'year' 'weekday'\n",
      " 'month' 'wx' 'wy' 'julian' 'h_lag1' 't_lag1' 'wx_lag1' 'wy_lag1'\n",
      " 'ws_lag1' 'dew_lag1' 'h_lag2' 't_lag2' 'wx_lag2' 'wy_lag2' 'ws_lag2'\n",
      " 'dew_lag2' 'h_lag3' 't_lag3' 'wx_lag3' 'wy_lag3' 'ws_lag3' 'dew_lag3']\n"
     ]
    }
   ],
   "source": [
    "# get names of all avaialable varaiables\n",
    "print('Variables available in the dataset:', df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose variable of interest & country\n",
    "in_var ='no2'\n",
    "loc = 'che'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Pollutant Distributions per Station\n",
    "\n",
    "Air pollutants are assumed to generally follow a lognormal distribution. The following code prodcues a histogram of the pollutant concentration for any station with a fitted lognormal density curve. It can be used to explore the dataframe and get a first indication whether this assumption holds true for all stations and helps detect abnormalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba08029424c461984a358ad291279df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='city', options=('Opfikon_Balsberg', 'StGallen_Blumenbergplatz', 'Sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def dist_lpot(city = cities):\n",
    "    df_city = df[df['city']==city]\n",
    "    sns.distplot(df_city[in_var], hist=True, kde=False, \n",
    "                 bins=int(180/5), color = 'blue', fit=stats.lognorm,\n",
    "                 hist_kws={'edgecolor':'black'})\n",
    "    # Add labels\n",
    "    plt.title(city)\n",
    "    plt.xlabel('PM25')\n",
    "    plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Algorithm\n",
    "\n",
    "The following function performs the model selection for a given city (i.e. station)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAMf_select(df, in_var, ex_vars, city, cut):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: \n",
    "        dataframe containing all variables of interest for the whole time of measurement\n",
    "    in_var: \n",
    "        independent variable\n",
    "    ex_vars: \n",
    "        list of explanatory variables\n",
    "    city: \n",
    "        name of specific city\n",
    "    cut: \n",
    "        string of the format '%m/%d/%Y' indicating the date when social distancing measures have been put into place\n",
    "    train_duration:\n",
    "        int, indicating the number of months that should be used for training\n",
    "        defaults to 'all' -> all available data before the cut date will be used as training data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    aic: \n",
    "        Akaike Information Criterion for the fitted Model\n",
    "    max_vif:\n",
    "        Highest Variance Inflation Factor for the fitted Model\n",
    "    \"\"\"\n",
    "\n",
    "    # subset dataset to given city\n",
    "    df = df[df['city']== city]\n",
    "    \n",
    "    # take only data until the date when social distancing measures have been put into place\n",
    "    cut = datetime.strptime(cut, '%m/%d/%Y')    \n",
    "    df_train = df[df.index<cut]\n",
    "    \n",
    "    # drop observations where not for all explanatory variables, measurements are available\n",
    "    df_train = df_train.dropna(subset=ex_vars)\n",
    "\n",
    "    # extract values for independent and explanatory variables\n",
    "    train_X = df_train[ex_vars].values\n",
    "    train_y = df_train[in_var].values\n",
    "    \n",
    "    # check if training set is not empty\n",
    "    # otherwise construct formula for the GAM model\n",
    "    if (len(train_X) != 0):\n",
    "        string = str()\n",
    "        if isinstance(ex_vars,str):\n",
    "            length = 1\n",
    "        else:\n",
    "            length = len(ex_vars)\n",
    "        for i in  range(0,length):\n",
    "            if (ex_vars[i] in ['weekday', 'month','season','hour','new_year', 'daytime']):\n",
    "                string = string + '+f(' + str(i) + ')'\n",
    "          #  else:  \n",
    "            if ('ws'in ex_vars[i]):\n",
    "                string = string + '+l('+ str(i) +')'\n",
    "            else:\n",
    "                string = string + '+s(' + str(i) + \", lam = 0.6, basis = 'ps')\"\n",
    "\n",
    "        string = string[1:]\n",
    "\n",
    "        # specify and get GAM model\n",
    "        gam = GAM(eval(string),\n",
    "                  distribution='normal', link='log')\n",
    "        # fit GAM Model\n",
    "        gam.fit(train_X, train_y) \n",
    "        \n",
    "        # calculate VIF\n",
    "        # set VIG to zero if we just have one explanatory variable\n",
    "        if len(ex_vars)==1:\n",
    "                max_vif =0\n",
    "        else:\n",
    "            vif = pd.DataFrame()\n",
    "            vif[\"VIF\"] = [variance_inflation_factor(train_X, i) for i in range(train_X.shape[1])]\n",
    "    \n",
    "            # get max observed VIF value\n",
    "            max_vif = max(vif['VIF'])\n",
    "\n",
    "        if max_vif is None:\n",
    "            print('Warning VIF', ex_vars)\n",
    "        elif gam.statistics_['AIC'] is None:\n",
    "            print('Warnig AIC', ex_vars)\n",
    "        else:\n",
    "            # return the AIC and the maximum VIF value\n",
    "            aic =gam.statistics_['AIC']\n",
    "            return(aic, max_vif)\n",
    "    else:\n",
    "        return(0, float('Inf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Model Selection\n",
    "\n",
    "In this part the dataframe is cleaned once more (i.e. we drop all observations were the independent variable is missing or has a negative value, which is impossible).\n",
    "\n",
    "The variable 'cut' has to be specified to define the dataset which is used to perform the model selection, i.e. this should be the date where COVID-19 lockdown measures were put into place in the country of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date of lockdown measures put in place\n",
    "cut = starts[loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns with NaN values or negative values for the observed variable\n",
    "df = df.replace(np.inf, np.nan)\n",
    "df = df.dropna(subset=[in_var])\n",
    "df = df.drop(df[df[in_var]<0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_vars_all = ['t', 'h', 'ws', 'dew',\n",
    " 'pca', 'lagpca_year', 'lagpca_halfyear', 'lagpca_12weeks', 'lagpca_8weeks',\n",
    " 'lagpca_4weeks', 'lagpca_2weeks', 'lagpca_1week', 'lagws_4weeks',\n",
    " 'lagws_2weeks', 'lagws_1week', 'lagws_4weeks_max', 'lagws_2weeks_max',\n",
    " 'lagws_1week_max', 'year', 'weekday', 'month', 'wx', 'wy', 'julian', 'h_lag1',\n",
    " 't_lag1', 'wx_lag1', 'wy_lag1', 'ws_lag1', 'dew_lag1', 'h_lag2', 't_lag2',\n",
    " 'wx_lag2', 'wy_lag2', 'ws_lag2', 'dew_lag2', 'h_lag3', 't_lag3', 'wx_lag3',\n",
    " 'wy_lag3', 'ws_lag3', 'dew_lag3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate column names for output datafram\n",
    "col_names = []\n",
    "model_names = []\n",
    "aic_names =[]\n",
    "j=1\n",
    "for i in ex_vars_all:\n",
    "    aic_names.append('var_'+ str(j))\n",
    "    aic_names.append('aic_'+ str(j))\n",
    "    aic_names.append('vif_'+ str(j))\n",
    "    j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opfikon_Balsberg Round # 1 :  julian\n",
      "Opfikon_Balsberg Round # 2 :  wy\n",
      "Opfikon_Balsberg Round # 3 :  weekday\n",
      "Opfikon_Balsberg Round # 4 :  pca\n",
      "Opfikon_Balsberg Round # 5 :  dew_lag2\n",
      "Opfikon_Balsberg Round # 6 :  wx_lag3\n",
      "StGallen_Blumenbergplatz Round # 1 :  julian\n",
      "StGallen_Blumenbergplatz Round # 2 :  weekday\n",
      "StGallen_Blumenbergplatz Round # 3 :  wx_lag1\n",
      "StGallen_Blumenbergplatz Round # 4 :  dew_lag1\n",
      "StGallen_Blumenbergplatz Round # 5 :  pca\n",
      "StGallen_Blumenbergplatz Round # 6 :  wx_lag3\n",
      "StGallen_Blumenbergplatz Round # 7 :  wx\n",
      "StGallen_Blumenbergplatz Round # 8 :  wx_lag2\n",
      "StGallen_Stuelegg Round # 1 :  t\n",
      "StGallen_Stuelegg Round # 2 :  ws\n",
      "StGallen_Stuelegg Round # 3 :  pca\n",
      "StGallen_Stuelegg Round # 4 :  wx_lag3\n",
      "StGallen_Stuelegg Round # 5 :  wy_lag3\n",
      "Zuerich_Schimmelstrasse Round # 1 :  ws_lag3\n",
      "Zuerich_Schimmelstrasse Round # 2 :  month\n",
      "Zuerich_Schimmelstrasse Round # 3 :  lagpca_1week\n",
      "Zuerich_Schimmelstrasse Round # 4 :  lagpca_8weeks\n",
      "Zuerich_Schimmelstrasse Round # 5 :  wx_lag2\n",
      "Zuerich_Stampfenbachstrasse Round # 1 :  julian\n",
      "Zuerich_Stampfenbachstrasse Round # 2 :  ws_lag2\n",
      "Zuerich_Stampfenbachstrasse Round # 3 :  lagpca_1week\n",
      "Zuerich_Stampfenbachstrasse Round # 4 :  lagpca_12weeks\n"
     ]
    }
   ],
   "source": [
    "# implementation of the model selection algorithm\n",
    "\n",
    "# initalise dataframes to collect output\n",
    "all_stats = pd.DataFrame(data = None, index = cities, columns = aic_names)\n",
    "chosen_vars = pd.DataFrame(data =None, index = cities)\n",
    "# make calculations for every city\n",
    "for city in cities:\n",
    "    \n",
    "    # initalise list & series to track outcomes\n",
    "    used_vars = list()\n",
    "    aics = pd.Series(data = None, index = ex_vars_all, dtype = 'float64')\n",
    "    vifs = pd.Series(data = None, index = ex_vars_all, dtype = 'float64')\n",
    "    \n",
    "    used_vars2 = list()\n",
    "    aics2 = pd.Series(data = None, index = ex_vars_all, dtype = 'float64')\n",
    "    vifs2 = pd.Series(data = None, index = ex_vars_all, dtype = 'float64')\n",
    "\n",
    "    # for every variable in the list of explanatory variables\n",
    "    for j in range(0, len(ex_vars_all)):\n",
    "        \n",
    "        # get a list of all variables that are not yet included in the model\n",
    "        ex_vars = [x for x in ex_vars_all if x not in used_vars]\n",
    "        \n",
    "        # for every variable not yet included in the model\n",
    "        for i, ex_var in enumerate(ex_vars):\n",
    "            gam_vars = used_vars.copy()\n",
    "            gam_vars.append(ex_var)\n",
    "            # fit a GAM model with the new variable added to the previous model & calculate AIC and VIF\n",
    "            if GAMf_select(df, in_var, gam_vars, city, cut) is None:\n",
    "                print('Error', city, gam_vars)\n",
    "            else:\n",
    "                aics[ex_var], vifs[ex_var] =  GAMf_select(df, in_var, gam_vars, city, cut)\n",
    "        #print(aics)\n",
    "        # filter all models with a maaximum VIF Score < 2.5\n",
    "        low = vifs[vifs<2.5].index\n",
    "\n",
    "        # if not for all models the included variables have a VIF Score > 2.5, select the model with the lowwest AIC\n",
    "        if (len(aics[low]) != 0):\n",
    "            chosen_var = aics[low].idxmin()\n",
    "        else:\n",
    "            break\n",
    "        # if the the AIC score is not lower than the one of the previous model -> stop \n",
    "        if chosen_var in used_vars:\n",
    "            break\n",
    "                        \n",
    "        # add selected variable and statistics to the all_stats Dataframe\n",
    "        all_stats.loc[city,aic_names[(j+1)*3-3]] = chosen_var\n",
    "        all_stats.loc[city, aic_names[(j+1)*3-2]] = aics[low].min()\n",
    "        all_stats.loc[city, aic_names[(j+1)*3-1]] = vifs[chosen_var]\n",
    "        \n",
    "        # add selected variable to the chosen_var Dataframe\n",
    "        used_vars.append(chosen_var)\n",
    "        chosen_vars.loc[city,j] = chosen_var\n",
    "        \n",
    "        print(city, 'Round #', str(j+1), ': ', chosen_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Opfikon_Balsberg</th>\n",
       "      <td>julian</td>\n",
       "      <td>wy</td>\n",
       "      <td>weekday</td>\n",
       "      <td>pca</td>\n",
       "      <td>dew_lag2</td>\n",
       "      <td>wx_lag3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StGallen_Blumenbergplatz</th>\n",
       "      <td>julian</td>\n",
       "      <td>weekday</td>\n",
       "      <td>wx_lag1</td>\n",
       "      <td>dew_lag1</td>\n",
       "      <td>pca</td>\n",
       "      <td>wx_lag3</td>\n",
       "      <td>wx</td>\n",
       "      <td>wx_lag2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StGallen_Stuelegg</th>\n",
       "      <td>t</td>\n",
       "      <td>ws</td>\n",
       "      <td>pca</td>\n",
       "      <td>wx_lag3</td>\n",
       "      <td>wy_lag3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuerich_Schimmelstrasse</th>\n",
       "      <td>ws_lag3</td>\n",
       "      <td>month</td>\n",
       "      <td>lagpca_1week</td>\n",
       "      <td>lagpca_8weeks</td>\n",
       "      <td>wx_lag2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuerich_Stampfenbachstrasse</th>\n",
       "      <td>julian</td>\n",
       "      <td>ws_lag2</td>\n",
       "      <td>lagpca_1week</td>\n",
       "      <td>lagpca_12weeks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0        1             2               3  \\\n",
       "Opfikon_Balsberg              julian       wy       weekday             pca   \n",
       "StGallen_Blumenbergplatz      julian  weekday       wx_lag1        dew_lag1   \n",
       "StGallen_Stuelegg                  t       ws           pca         wx_lag3   \n",
       "Zuerich_Schimmelstrasse      ws_lag3    month  lagpca_1week   lagpca_8weeks   \n",
       "Zuerich_Stampfenbachstrasse   julian  ws_lag2  lagpca_1week  lagpca_12weeks   \n",
       "\n",
       "                                    4        5    6        7  \n",
       "Opfikon_Balsberg             dew_lag2  wx_lag3  NaN      NaN  \n",
       "StGallen_Blumenbergplatz          pca  wx_lag3   wx  wx_lag2  \n",
       "StGallen_Stuelegg             wy_lag3      NaN  NaN      NaN  \n",
       "Zuerich_Schimmelstrasse       wx_lag2      NaN  NaN      NaN  \n",
       "Zuerich_Stampfenbachstrasse       NaN      NaN  NaN      NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print table with the variables for each station chosen by the selection algorithm\n",
    "chosen_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dew_lag1          1.0\n",
       "dew_lag2          1.0\n",
       "julian            3.0\n",
       "lagpca_12weeks    1.0\n",
       "lagpca_1week      2.0\n",
       "lagpca_8weeks     1.0\n",
       "month             1.0\n",
       "pca               3.0\n",
       "t                 1.0\n",
       "weekday           2.0\n",
       "ws                1.0\n",
       "ws_lag2           1.0\n",
       "ws_lag3           1.0\n",
       "wx                1.0\n",
       "wx_lag1           1.0\n",
       "wx_lag2           2.0\n",
       "wx_lag3           3.0\n",
       "wy                1.0\n",
       "wy_lag3           1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print table with the total count of how often each variable was chosen\n",
    "chosen_vars.apply(pd.value_counts).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output to csv\n",
    "chosen_vars.to_csv('./' + loc + '/' + in_var + '_chosen_vars.csv')\n",
    "all_stats.to_csv('./' + loc + '/' + in_var +'_all_stats.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
